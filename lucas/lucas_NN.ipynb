{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classic pydata stack\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sys\n",
    "%matplotlib inline \n",
    "\n",
    "from NN import *\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15,7)\n",
    "\n",
    "\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## SEEDING\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "REBUILD_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks=5\n",
    "\n",
    "\n",
    "dataset = PolymerDataset(data_paths=[\"../data/AA66266AA.npy\",\"../data/AA662266AA.npy\"],num_blocks=num_blocks,lstm=True)\n",
    "num_features = dataset.data[0].shape[1]\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/299, loss=0.5182722806930542, accuracy=76.92717742919922\n",
      "epoch=50/299, loss=0.26967522501945496, accuracy=90.32682037353516\n",
      "epoch=100/299, loss=0.21589510142803192, accuracy=90.96980285644531\n",
      "epoch=150/299, loss=0.17336080968379974, accuracy=91.42095947265625\n",
      "epoch=200/299, loss=0.1254599392414093, accuracy=91.66607666015625\n",
      "epoch=250/299, loss=0.21873962879180908, accuracy=91.82948303222656\n",
      "epoch=299/299, loss=0.2792649269104004, accuracy=92.06749725341797\n"
     ]
    }
   ],
   "source": [
    "model = LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=4, num_epochs=300, batch_size=64, lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_loader):\n",
    "    predictions = np.array([])\n",
    "    labels = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in iter(data_loader):\n",
    "            probs = model(X)\n",
    "            preds = torch.argmax(probs, dim=1, keepdim=False)\n",
    "            predictions = np.concatenate((predictions,preds), axis=None)\n",
    "            labels= np.concatenate((labels,y),axis=None)\n",
    "\n",
    "    return(accuracy_score(labels,predictions), f1_score(labels,predictions))\n",
    "\n",
    "    print(confusion_matrix(labels,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "params_list={\n",
    "\n",
    "###\n",
    "# Feature engineering param\n",
    "\n",
    "\"auto_corr\":[True,False],\n",
    "\"num_blocks\":[5,6,7], #Keep num_blocks as last database parameter in order to optimize dataset building\n",
    "\n",
    "####\n",
    "# Optimizer and model params\n",
    "\n",
    "\"lr\":[0.005,0.001, 0.0005],\n",
    "\"hidden_dim\":[4,5,6],\n",
    "\"num_epochs\":[10,50,80],\n",
    "\n",
    "}\n",
    "param_combinations = list(it.product(*(params_list[param_name] for param_name in params_list.keys())))\n",
    "print(len(param_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params_list):\n",
    "    param_combinations = list(it.product(*(params_list[param_name] for param_name in params_list.keys())))\n",
    "\n",
    "    best_accuracy=0\n",
    "    last_num_blocks=-1\n",
    "   \n",
    "    for params in param_combinations:\n",
    "        kwargs={}\n",
    "        for i,key in enumerate(params_list):\n",
    "            kwargs[key]=params[i]\n",
    "        if kwargs.get(\"num_blocks\",1)!=last_num_blocks:\n",
    "            dataset = PolymerDataset(data_paths=[\"../data/AA66266AA.npy\",\"../data/AA662266AA.npy\"],num_blocks=kwargs.get(\"num_blocks\",1),lstm=True, auto_corr=kwargs.pop(\"auto_corr\"))\n",
    "            train_size = int(0.8 * len(dataset))\n",
    "            test_size = len(dataset) - train_size\n",
    "            train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "            data_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "        else:\n",
    "            kwargs.pop(\"auto_corr\")\n",
    "        print(kwargs)\n",
    "        model = LSTM.train(dataset=train_data, num_features=num_features, batch_size=64, **kwargs)\n",
    "        test_accuracy, test_f1 = test_model(model, data_loader)\n",
    "        if test_accuracy>best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            best_f1=test_f1\n",
    "            best_model=model\n",
    "            best_params=kwargs\n",
    "            with open('best_params.txt', 'w') as f:\n",
    "                f.write(\"Best accuracy ({}) and f1 ({}) were reached with params {}\".format(best_accuracy,best_f1, best_params))        \n",
    "                    \n",
    "        last_num_blocks=kwargs.get(\"num_blocks\",1)\n",
    "    print(\"Best accuracy ({}) and f1 ({}) were reached with params {}\".format(best_accuracy,best_f1, best_params))\n",
    "    return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58448ef5cac463726b881fca7d37b594423fb753b33189a3ab7441d7486b15aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ml4science': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
