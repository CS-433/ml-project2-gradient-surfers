{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## classic pydata stack\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "from NN_LSTM import *\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15,7)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import itertools as it\n",
    "from datetime import datetime\n",
    "\n",
    "## torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "## SEEDING\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "REBUILD_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_loader):\n",
    "    predictions = np.array([])\n",
    "    labels = np.array([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in iter(data_loader):\n",
    "            probs = model(X)\n",
    "            preds = torch.argmax(probs, dim=1, keepdim=False)\n",
    "            predictions = np.concatenate((predictions,preds), axis=None)\n",
    "            labels= np.concatenate((labels,y),axis=None)\n",
    "\n",
    "    return(accuracy_score(labels,predictions), f1_score(labels,predictions))\n",
    "\n",
    "    print(confusion_matrix(labels,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###\n",
    "# Feature engineering param\n",
    "dataset_params_list={\n",
    "    \"psd\":[False],\n",
    "    \"auto_corr\":[False],\n",
    "    \"num_blocks\":[30,20],\n",
    "}\n",
    "\n",
    "\n",
    "####\n",
    "# Optimizer and model params\n",
    "model_params_list={\n",
    "\n",
    "\"nn_specs\": #Make sure that there are as much linear layers dims than activation function\n",
    "    [\n",
    "    ([8,8],[nn.Tanh(),nn.Tanh()]), \n",
    "    ],\n",
    "\n",
    "\n",
    "\"hidden_dim\":[20,10],\n",
    "\"lr\":[0.001],\n",
    "\"rstm_layers\":[5,3,1],\n",
    "\"num_epochs\":[400],\n",
    "\n",
    "}\n",
    "\n",
    "dataset_param_combinations = list(it.product(*(dataset_params_list[param_name] for param_name in dataset_params_list.keys())))\n",
    "\n",
    "model_param_combinations = list(it.product(*(model_params_list[param_name] for param_name in model_params_list.keys())))\n",
    "\n",
    "print(len(model_param_combinations)*len(dataset_param_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(dataset_params_list, model_params_list):\n",
    "\n",
    "    dataset_param_combinations = list(it.product(*(dataset_params_list[param_name] for param_name in dataset_params_list.keys())))\n",
    "\n",
    "    model_param_combinations = list(it.product(*(model_params_list[param_name] for param_name in model_params_list.keys())))\n",
    "\n",
    "    best_accuracy=0\n",
    "\n",
    "    with open(\"cv_logs_{}.txt\".format(datetime.now()), \"a\") as f_logs:\n",
    "        ds_kwargs={}\n",
    "        for ds_params in dataset_param_combinations:\n",
    "            for i,key in enumerate(dataset_params_list):\n",
    "                ds_kwargs[key]=ds_params[i]\n",
    "\n",
    "            dataset = PolymerDataset(data_paths=[\"../data/AA66266AA.npy\",\"../data/AA662266AA.npy\"],lstm=True, **ds_kwargs)\n",
    "            train_size = int(0.8 * len(dataset))\n",
    "            test_size = len(dataset) - train_size\n",
    "            train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "            data_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "            num_features = dataset.data[0].shape[1]\n",
    "            \n",
    "            for model_params in model_param_combinations:\n",
    "                model_kwargs={}\n",
    "                for i,key in enumerate(model_params_list):\n",
    "                    model_kwargs[key]=model_params[i]\n",
    "\n",
    "                print(ds_kwargs | model_kwargs)\n",
    "\n",
    "                model = LSTM.train(dataset=train_data, num_features=num_features, batch_size=64, num_blocks=ds_kwargs[\"num_blocks\"], **model_kwargs)\n",
    "                test_accuracy, test_f1 = test_model(model, data_loader)\n",
    "\n",
    "                f_logs.write(\"Accuracy = {} | F1 = {} with params : {} \\n\".format(test_accuracy,test_f1, ds_kwargs| model_kwargs))\n",
    "                f_logs.flush()\n",
    "\n",
    "                if test_accuracy>best_accuracy:\n",
    "                    best_accuracy = test_accuracy\n",
    "                    best_f1=test_f1\n",
    "                    best_model=model\n",
    "                    best_params=ds_kwargs | model_kwargs\n",
    "\n",
    "                    with open('best_params.txt', 'w') as f:\n",
    "                        f.write(\"Best accuracy ({}) and f1 ({}) were reached with params {} \\n\".format(best_accuracy,best_f1, best_params))  \n",
    "                        #for param in best_model.parameters():\n",
    "                        #    f.write(param.data) \n",
    "                        f.close()\n",
    "\n",
    "        print(\"Best accuracy ({}) and f1 ({}) were reached with params {}\".format(best_accuracy,best_f1, best_params))\n",
    "        f_logs.close()\n",
    "        return best_model, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'psd': False, 'auto_corr': False, 'num_blocks': 20, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7309266328811646, accuracy=48.06749725341797\n",
      "epoch=50/399, loss=0.1605028361082077, accuracy=90.58259582519531\n",
      "epoch=100/399, loss=0.18715010583400726, accuracy=91.66252136230469\n",
      "epoch=150/399, loss=0.1308804154396057, accuracy=92.37655639648438\n",
      "epoch=200/399, loss=0.21947576105594635, accuracy=92.80994415283203\n",
      "epoch=250/399, loss=0.2000802904367447, accuracy=93.03730010986328\n",
      "epoch=300/399, loss=0.07575014978647232, accuracy=93.31438446044922\n",
      "epoch=350/399, loss=0.25947287678718567, accuracy=93.53108215332031\n",
      "epoch=399/399, loss=0.11465419828891754, accuracy=93.63410186767578\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 20, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.47779297828674316, accuracy=67.95026397705078\n",
      "epoch=50/399, loss=0.21155402064323425, accuracy=90.93072509765625\n",
      "epoch=100/399, loss=0.19832812249660492, accuracy=91.79751586914062\n",
      "epoch=150/399, loss=0.16830138862133026, accuracy=92.37300109863281\n",
      "epoch=200/399, loss=0.11579132080078125, accuracy=92.63232421875\n",
      "epoch=250/399, loss=0.12258464097976685, accuracy=92.95914459228516\n",
      "epoch=300/399, loss=0.13476411998271942, accuracy=93.32859802246094\n",
      "epoch=350/399, loss=0.12396397441625595, accuracy=93.31793975830078\n",
      "epoch=399/399, loss=0.11457204073667526, accuracy=93.61278533935547\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 20, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.5021557807922363, accuracy=61.21847152709961\n",
      "epoch=50/399, loss=0.3501514494419098, accuracy=90.89165496826172\n",
      "epoch=100/399, loss=0.4295003116130829, accuracy=91.63765716552734\n",
      "epoch=150/399, loss=0.28521978855133057, accuracy=92.0994644165039\n",
      "epoch=200/399, loss=0.22034060955047607, accuracy=92.2806396484375\n",
      "epoch=250/399, loss=0.19520454108715057, accuracy=92.53996276855469\n",
      "epoch=300/399, loss=0.2753126919269562, accuracy=92.8703384399414\n",
      "epoch=350/399, loss=0.21637852489948273, accuracy=93.00532531738281\n",
      "epoch=399/399, loss=0.16919641196727753, accuracy=92.8490219116211\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 20, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7191191911697388, accuracy=49.28596878051758\n",
      "epoch=50/399, loss=0.31978222727775574, accuracy=90.5186538696289\n",
      "epoch=100/399, loss=0.25361740589141846, accuracy=91.80461883544922\n",
      "epoch=150/399, loss=0.1754220575094223, accuracy=92.0426254272461\n",
      "epoch=200/399, loss=0.287595272064209, accuracy=92.46536254882812\n",
      "epoch=250/399, loss=0.23514777421951294, accuracy=92.82770538330078\n",
      "epoch=300/399, loss=0.06725339591503143, accuracy=92.89875793457031\n",
      "epoch=350/399, loss=0.06661406904459, accuracy=93.09058380126953\n",
      "epoch=399/399, loss=0.34734129905700684, accuracy=93.17584228515625\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 20, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7346066236495972, accuracy=48.0035514831543\n",
      "epoch=50/399, loss=0.2912491261959076, accuracy=90.4973373413086\n",
      "epoch=100/399, loss=0.0819380134344101, accuracy=91.3960952758789\n",
      "epoch=150/399, loss=0.06221862509846687, accuracy=91.93250274658203\n",
      "epoch=200/399, loss=0.2983218729496002, accuracy=92.39431762695312\n",
      "epoch=250/399, loss=0.13441354036331177, accuracy=92.76376342773438\n",
      "epoch=300/399, loss=0.346919447183609, accuracy=92.98401641845703\n",
      "epoch=350/399, loss=0.15628565847873688, accuracy=93.21492004394531\n",
      "epoch=399/399, loss=0.1658574789762497, accuracy=93.27531433105469\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 20, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.7120316028594971, accuracy=51.765541076660156\n",
      "epoch=50/399, loss=0.22018998861312866, accuracy=90.38365936279297\n",
      "epoch=100/399, loss=0.16834838688373566, accuracy=91.39964294433594\n",
      "epoch=150/399, loss=0.15435785055160522, accuracy=91.6909408569336\n",
      "epoch=200/399, loss=0.07727361470460892, accuracy=92.14209747314453\n",
      "epoch=250/399, loss=0.17888562381267548, accuracy=92.10657501220703\n",
      "epoch=300/399, loss=0.26252999901771545, accuracy=92.3516845703125\n",
      "epoch=350/399, loss=0.22944270074367523, accuracy=92.45115661621094\n",
      "epoch=399/399, loss=0.18949460983276367, accuracy=92.55062103271484\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 3, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7138363122940063, accuracy=50.10301971435547\n",
      "epoch=50/399, loss=0.2881923317909241, accuracy=88.22024536132812\n",
      "epoch=100/399, loss=0.2161921113729477, accuracy=89.60923767089844\n",
      "epoch=150/399, loss=0.24509920179843903, accuracy=90.3445816040039\n",
      "epoch=200/399, loss=0.41523948311805725, accuracy=90.7779769897461\n",
      "epoch=250/399, loss=0.27966630458831787, accuracy=91.24333953857422\n",
      "epoch=300/399, loss=0.21849550306797028, accuracy=91.22557830810547\n",
      "epoch=350/399, loss=0.21431738138198853, accuracy=91.39253997802734\n",
      "epoch=399/399, loss=0.29750460386276245, accuracy=91.48490142822266\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 3, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7240071296691895, accuracy=43.29307174682617\n",
      "epoch=50/399, loss=0.19756677746772766, accuracy=88.67140197753906\n",
      "epoch=100/399, loss=0.20241039991378784, accuracy=89.85079956054688\n",
      "epoch=150/399, loss=0.19746817648410797, accuracy=90.51154327392578\n",
      "epoch=200/399, loss=0.34825003147125244, accuracy=90.8490219116211\n",
      "epoch=250/399, loss=0.1883215308189392, accuracy=90.94849395751953\n",
      "epoch=300/399, loss=0.17441514134407043, accuracy=91.193603515625\n",
      "epoch=350/399, loss=0.19853414595127106, accuracy=91.36412048339844\n",
      "epoch=399/399, loss=0.3363068997859955, accuracy=91.4103012084961\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 3, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.7133114337921143, accuracy=51.31793975830078\n",
      "epoch=50/399, loss=0.16322939097881317, accuracy=88.8134994506836\n",
      "epoch=100/399, loss=0.3037637174129486, accuracy=90.071044921875\n",
      "epoch=150/399, loss=0.33170533180236816, accuracy=90.62877655029297\n",
      "epoch=200/399, loss=0.19436174631118774, accuracy=90.72468566894531\n",
      "epoch=250/399, loss=0.2501072287559509, accuracy=90.95204162597656\n",
      "epoch=300/399, loss=0.1490132063627243, accuracy=91.28596496582031\n",
      "epoch=350/399, loss=0.2938686013221741, accuracy=91.31793975830078\n",
      "epoch=399/399, loss=0.3057388961315155, accuracy=91.45293426513672\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 3, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.71634840965271, accuracy=49.9680290222168\n",
      "epoch=50/399, loss=0.39988940954208374, accuracy=86.98401641845703\n",
      "epoch=100/399, loss=0.2942923903465271, accuracy=88.72468566894531\n",
      "epoch=150/399, loss=0.17623396217823029, accuracy=89.1651840209961\n",
      "epoch=200/399, loss=0.38979631662368774, accuracy=90.24156188964844\n",
      "epoch=250/399, loss=0.15140067040920258, accuracy=90.58259582519531\n",
      "epoch=300/399, loss=0.21711787581443787, accuracy=90.89520263671875\n",
      "epoch=350/399, loss=0.20961526036262512, accuracy=91.14031982421875\n",
      "epoch=399/399, loss=0.1628781259059906, accuracy=91.07282257080078\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 3, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7177310585975647, accuracy=49.637657165527344\n",
      "epoch=50/399, loss=0.25483402609825134, accuracy=88.48667907714844\n",
      "epoch=100/399, loss=0.19805096089839935, accuracy=90.13499450683594\n",
      "epoch=150/399, loss=0.1872323602437973, accuracy=90.9769058227539\n",
      "epoch=200/399, loss=0.4044889807701111, accuracy=91.00177764892578\n",
      "epoch=250/399, loss=0.27905192971229553, accuracy=91.14387512207031\n",
      "epoch=300/399, loss=0.09322935342788696, accuracy=91.30728149414062\n",
      "epoch=350/399, loss=0.09760119020938873, accuracy=91.42451477050781\n",
      "epoch=399/399, loss=0.15926940739154816, accuracy=91.44227600097656\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 3, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.7094389796257019, accuracy=49.62699890136719\n",
      "epoch=50/399, loss=0.4291994571685791, accuracy=88.31261444091797\n",
      "epoch=100/399, loss=0.36213135719299316, accuracy=89.52753448486328\n",
      "epoch=150/399, loss=0.1671294867992401, accuracy=90.06039428710938\n",
      "epoch=200/399, loss=0.16253109276294708, accuracy=90.50088500976562\n",
      "epoch=250/399, loss=0.1490405648946762, accuracy=90.62877655029297\n",
      "epoch=300/399, loss=0.18575610220432281, accuracy=90.71403503417969\n",
      "epoch=350/399, loss=0.29380911588668823, accuracy=90.92362213134766\n",
      "epoch=399/399, loss=0.2813403308391571, accuracy=91.20781707763672\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 5, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7173842191696167, accuracy=50.131439208984375\n",
      "epoch=50/399, loss=0.2459491342306137, accuracy=89.26820373535156\n",
      "epoch=100/399, loss=0.2649412453174591, accuracy=90.11722564697266\n",
      "epoch=150/399, loss=0.2033495008945465, accuracy=90.63587951660156\n",
      "epoch=200/399, loss=0.2576494812965393, accuracy=91.35346221923828\n",
      "epoch=250/399, loss=0.23388153314590454, accuracy=91.81172180175781\n",
      "epoch=300/399, loss=0.06371768563985825, accuracy=91.88632202148438\n",
      "epoch=350/399, loss=0.22998693585395813, accuracy=92.13499450683594\n",
      "epoch=399/399, loss=0.13161848485469818, accuracy=92.3232650756836\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 5, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7130064368247986, accuracy=48.44404983520508\n",
      "epoch=50/399, loss=0.29964134097099304, accuracy=89.4103012084961\n",
      "epoch=100/399, loss=0.26929670572280884, accuracy=90.42273712158203\n",
      "epoch=150/399, loss=0.11417277902364731, accuracy=91.17939758300781\n",
      "epoch=200/399, loss=0.0839942991733551, accuracy=91.57015991210938\n",
      "epoch=250/399, loss=0.19192573428153992, accuracy=92.16341400146484\n",
      "epoch=300/399, loss=0.16185162961483002, accuracy=92.33392333984375\n",
      "epoch=350/399, loss=0.07779941707849503, accuracy=92.4973373413086\n",
      "epoch=399/399, loss=0.1848851889371872, accuracy=92.43694305419922\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 5, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.7254657745361328, accuracy=51.53108215332031\n",
      "epoch=50/399, loss=0.32597827911376953, accuracy=89.33570098876953\n",
      "epoch=100/399, loss=0.18401479721069336, accuracy=90.25577545166016\n",
      "epoch=150/399, loss=0.19406235218048096, accuracy=91.01953887939453\n",
      "epoch=200/399, loss=0.2731916904449463, accuracy=91.60568237304688\n",
      "epoch=250/399, loss=0.2931877672672272, accuracy=91.6483154296875\n",
      "epoch=300/399, loss=0.27602842450141907, accuracy=91.76909637451172\n",
      "epoch=350/399, loss=0.19052278995513916, accuracy=91.89698028564453\n",
      "epoch=399/399, loss=0.22847823798656464, accuracy=91.97868347167969\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 5, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7119053602218628, accuracy=48.0355224609375\n",
      "epoch=50/399, loss=0.20070745050907135, accuracy=88.50444030761719\n",
      "epoch=100/399, loss=0.3287748694419861, accuracy=89.69449615478516\n",
      "epoch=150/399, loss=0.22265468537807465, accuracy=90.01776123046875\n",
      "epoch=200/399, loss=0.2413562834262848, accuracy=90.5968017578125\n",
      "epoch=250/399, loss=0.09649357199668884, accuracy=91.0941390991211\n",
      "epoch=300/399, loss=0.2504517138004303, accuracy=91.38188171386719\n",
      "epoch=350/399, loss=0.17881979048252106, accuracy=91.73357391357422\n",
      "epoch=399/399, loss=0.13000869750976562, accuracy=91.7548828125\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 5, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7163903713226318, accuracy=48.429840087890625\n",
      "epoch=50/399, loss=0.15074382722377777, accuracy=89.10834503173828\n",
      "epoch=100/399, loss=0.14938661456108093, accuracy=89.81527709960938\n",
      "epoch=150/399, loss=0.2919105887413025, accuracy=90.47957611083984\n",
      "epoch=200/399, loss=0.24333038926124573, accuracy=90.80284118652344\n",
      "epoch=250/399, loss=0.1784793883562088, accuracy=91.55950164794922\n",
      "epoch=300/399, loss=0.13577869534492493, accuracy=91.7548828125\n",
      "epoch=350/399, loss=0.3494361639022827, accuracy=91.92539978027344\n",
      "epoch=399/399, loss=0.19893606007099152, accuracy=92.13143920898438\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 5, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.7110241055488586, accuracy=47.928951263427734\n",
      "epoch=50/399, loss=0.20455148816108704, accuracy=89.41740417480469\n",
      "epoch=100/399, loss=0.2015937715768814, accuracy=89.89698028564453\n",
      "epoch=150/399, loss=0.463584303855896, accuracy=90.54706573486328\n",
      "epoch=200/399, loss=0.1740243285894394, accuracy=90.88809967041016\n",
      "epoch=250/399, loss=0.23816753923892975, accuracy=91.4813461303711\n",
      "epoch=300/399, loss=0.2880527079105377, accuracy=91.55595397949219\n",
      "epoch=350/399, loss=0.22248941659927368, accuracy=91.82238006591797\n",
      "epoch=399/399, loss=0.41025522351264954, accuracy=92.00355529785156\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 10, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7187310457229614, accuracy=47.772647857666016\n",
      "epoch=50/399, loss=0.13811884820461273, accuracy=90.7708740234375\n",
      "epoch=100/399, loss=0.4052661955356598, accuracy=91.83658599853516\n",
      "epoch=150/399, loss=0.18351098895072937, accuracy=92.68561553955078\n",
      "epoch=200/399, loss=0.1685284972190857, accuracy=92.9129638671875\n",
      "epoch=250/399, loss=0.26105424761772156, accuracy=93.15452575683594\n",
      "epoch=300/399, loss=0.2532147169113159, accuracy=93.2291259765625\n",
      "epoch=350/399, loss=0.1480848342180252, accuracy=93.4031982421875\n",
      "epoch=399/399, loss=0.1441059708595276, accuracy=93.509765625\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 10, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7220199704170227, accuracy=47.11545181274414\n",
      "epoch=50/399, loss=0.22744764387607574, accuracy=90.3232650756836\n",
      "epoch=100/399, loss=0.1271294504404068, accuracy=91.44227600097656\n",
      "epoch=150/399, loss=0.36263740062713623, accuracy=92.23090362548828\n",
      "epoch=200/399, loss=0.19870974123477936, accuracy=92.69982147216797\n",
      "epoch=250/399, loss=0.10456844419240952, accuracy=92.9129638671875\n",
      "epoch=300/399, loss=0.10114288330078125, accuracy=93.09769439697266\n",
      "epoch=350/399, loss=0.07454288750886917, accuracy=93.26465606689453\n",
      "epoch=399/399, loss=0.29324871301651, accuracy=93.4671401977539\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 10, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.7230815291404724, accuracy=47.92539978027344\n",
      "epoch=50/399, loss=0.23358191549777985, accuracy=90.58614349365234\n",
      "epoch=100/399, loss=0.10513024777173996, accuracy=91.38898468017578\n",
      "epoch=150/399, loss=0.26864707469940186, accuracy=91.97868347167969\n",
      "epoch=200/399, loss=0.1348302960395813, accuracy=92.2877426147461\n",
      "epoch=250/399, loss=0.08496806025505066, accuracy=92.5328598022461\n",
      "epoch=300/399, loss=0.23176686465740204, accuracy=92.7779769897461\n",
      "epoch=350/399, loss=0.13741666078567505, accuracy=92.94493865966797\n",
      "epoch=399/399, loss=0.2447303831577301, accuracy=93.02664184570312\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 10, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 5, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7163046598434448, accuracy=49.7158088684082\n",
      "epoch=50/399, loss=0.4321558177471161, accuracy=90.24866485595703\n",
      "epoch=100/399, loss=0.18410737812519073, accuracy=91.00177764892578\n",
      "epoch=150/399, loss=0.2627924680709839, accuracy=91.49200439453125\n",
      "epoch=200/399, loss=0.23817314207553864, accuracy=92.00355529785156\n",
      "epoch=250/399, loss=0.2404676377773285, accuracy=92.15275573730469\n",
      "epoch=300/399, loss=0.18002282083034515, accuracy=92.33392333984375\n",
      "epoch=350/399, loss=0.2732779383659363, accuracy=92.54351806640625\n",
      "epoch=399/399, loss=0.23774488270282745, accuracy=92.54351806640625\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 10, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 3, 'num_epochs': 400}\n",
      "epoch=0/399, loss=0.7263187170028687, accuracy=44.831260681152344\n",
      "epoch=50/399, loss=0.33662980794906616, accuracy=89.73001861572266\n",
      "epoch=100/399, loss=0.25252506136894226, accuracy=90.806396484375\n",
      "epoch=150/399, loss=0.16007988154888153, accuracy=91.509765625\n",
      "epoch=200/399, loss=0.20420102775096893, accuracy=91.9715805053711\n",
      "epoch=250/399, loss=0.20708608627319336, accuracy=92.35879516601562\n",
      "epoch=300/399, loss=0.218145489692688, accuracy=92.69271850585938\n",
      "epoch=350/399, loss=0.297201931476593, accuracy=92.806396484375\n",
      "epoch=399/399, loss=0.1201610416173935, accuracy=92.99822235107422\n",
      "{'psd': False, 'auto_corr': False, 'num_blocks': 10, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 8, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucastrg/FLEP/MA1/ML/ml4science-polymers/ml4science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/399, loss=0.7120599150657654, accuracy=48.68916702270508\n",
      "epoch=50/399, loss=0.2652615010738373, accuracy=90.29129791259766\n",
      "epoch=100/399, loss=0.1555413156747818, accuracy=91.24689483642578\n",
      "epoch=150/399, loss=0.13259641826152802, accuracy=91.77264404296875\n",
      "epoch=200/399, loss=0.30524271726608276, accuracy=92.2095947265625\n",
      "epoch=250/399, loss=0.09019938856363297, accuracy=92.39431762695312\n",
      "epoch=300/399, loss=0.16046041250228882, accuracy=92.38365936279297\n",
      "epoch=350/399, loss=0.16849100589752197, accuracy=92.55772399902344\n",
      "epoch=399/399, loss=0.180532768368721, accuracy=92.59325408935547\n",
      "Best accuracy (0.927536231884058) and f1 (0.9280474040632054) were reached with params {'psd': False, 'auto_corr': False, 'num_blocks': 20, 'nn_specs': ([8, 8], [Tanh(), Tanh()]), 'hidden_dim': 10, 'lr': 0.001, 'rstm_layers': 1, 'num_epochs': 400}\n"
     ]
    }
   ],
   "source": [
    "best_model, best_params= grid_search(dataset_params_list, model_params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58448ef5cac463726b881fca7d37b594423fb753b33189a3ab7441d7486b15aa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ml4science': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
