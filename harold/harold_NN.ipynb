{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "## classic pydata stack\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15,7)\n",
    "\n",
    "\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## SEEDING\n",
    "\n",
    "\n",
    "\n",
    "REBUILD_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import vanilla_NN as NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report notes\n",
    "\n",
    "- need to filter out signals that are too long because the length distribution between the two datasets is very important\n",
    "- need to balance datasets because one dataset is much bigger than the other\n",
    "- process the data such that an RNN or any NN can process it\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks=10\n",
    "dataset = NN.PolymerDataset(data_paths=[\"AA66466AA.npy\",\"AA66266AA.npy\"],num_blocks=num_blocks,lstm=True)\n",
    "num_features = dataset.data[0].shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/49, loss=0.31304627656936646, accuracy=73.79396057128906\n",
      "epoch=1/49, loss=0.3067774474620819, accuracy=81.02664184570312\n",
      "epoch=2/49, loss=0.3299972414970398, accuracy=81.7904052734375\n",
      "epoch=3/49, loss=0.26985618472099304, accuracy=82.62877655029297\n",
      "epoch=4/49, loss=0.27726274728775024, accuracy=82.92717742919922\n",
      "epoch=5/49, loss=0.28162452578544617, accuracy=83.22557830810547\n",
      "epoch=6/49, loss=0.33179762959480286, accuracy=83.24689483642578\n",
      "epoch=7/49, loss=0.32970964908599854, accuracy=83.69449615478516\n",
      "epoch=8/49, loss=0.21187373995780945, accuracy=83.75843811035156\n",
      "epoch=9/49, loss=0.2885851562023163, accuracy=83.83303833007812\n",
      "epoch=10/49, loss=0.41887956857681274, accuracy=84.08525848388672\n",
      "epoch=11/49, loss=0.31746137142181396, accuracy=84.03197479248047\n",
      "epoch=12/49, loss=0.2851174473762512, accuracy=84.28419494628906\n",
      "epoch=13/49, loss=0.2714103162288666, accuracy=84.22024536132812\n",
      "epoch=14/49, loss=0.3374994099140167, accuracy=84.42273712158203\n",
      "epoch=15/49, loss=0.2538404166698456, accuracy=84.48312377929688\n",
      "epoch=16/49, loss=0.2147703319787979, accuracy=84.490234375\n",
      "epoch=17/49, loss=0.2105720192193985, accuracy=84.74955749511719\n",
      "epoch=18/49, loss=0.38674283027648926, accuracy=84.5968017578125\n",
      "epoch=19/49, loss=0.2903362512588501, accuracy=84.68916320800781\n",
      "epoch=20/49, loss=0.42178061604499817, accuracy=84.68916320800781\n",
      "epoch=21/49, loss=0.21137790381908417, accuracy=84.87744140625\n",
      "epoch=22/49, loss=0.3231426775455475, accuracy=84.96269989013672\n",
      "epoch=23/49, loss=0.24908722937107086, accuracy=85.0230941772461\n",
      "epoch=24/49, loss=0.4430537521839142, accuracy=84.99822235107422\n",
      "epoch=25/49, loss=0.2766329050064087, accuracy=85.29307556152344\n",
      "epoch=26/49, loss=0.2593832314014435, accuracy=84.95914459228516\n",
      "epoch=27/49, loss=0.24719169735908508, accuracy=85.29662322998047\n",
      "epoch=28/49, loss=0.3176523447036743, accuracy=85.0586166381836\n",
      "epoch=29/49, loss=0.257388174533844, accuracy=85.04795837402344\n",
      "epoch=30/49, loss=0.310608446598053, accuracy=85.24689483642578\n",
      "epoch=31/49, loss=0.39895713329315186, accuracy=85.25044250488281\n",
      "epoch=32/49, loss=0.28260838985443115, accuracy=85.25399780273438\n",
      "epoch=33/49, loss=0.445629358291626, accuracy=85.42095947265625\n",
      "epoch=34/49, loss=0.41592928767204285, accuracy=85.40674591064453\n",
      "epoch=35/49, loss=0.2524237334728241, accuracy=85.35346221923828\n",
      "epoch=36/49, loss=0.29430028796195984, accuracy=85.33214569091797\n",
      "epoch=37/49, loss=0.36976146697998047, accuracy=85.3747787475586\n",
      "epoch=38/49, loss=0.37305551767349243, accuracy=85.43516540527344\n",
      "epoch=39/49, loss=0.3301258683204651, accuracy=85.29307556152344\n",
      "epoch=40/49, loss=0.38763734698295593, accuracy=85.38188171386719\n",
      "epoch=41/49, loss=0.40745508670806885, accuracy=85.35701751708984\n",
      "epoch=42/49, loss=0.2185356765985489, accuracy=85.38898468017578\n",
      "epoch=43/49, loss=0.25696539878845215, accuracy=85.48490142822266\n",
      "epoch=44/49, loss=0.3340975344181061, accuracy=85.38188171386719\n",
      "epoch=45/49, loss=0.3049635589122772, accuracy=85.4742431640625\n",
      "epoch=46/49, loss=0.2922230064868927, accuracy=85.57015991210938\n",
      "epoch=47/49, loss=0.3822626769542694, accuracy=85.56660461425781\n",
      "epoch=48/49, loss=0.4031226336956024, accuracy=85.47779846191406\n",
      "epoch=49/49, loss=0.22220094501972198, accuracy=85.55950164794922\n"
     ]
    }
   ],
   "source": [
    "model = NN.LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=12, num_epochs=50, batch_size=64, lr=0.001, weight_decay=0.0001, verbose='vv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.06%\n",
      "F1 Score: 84.19%\n",
      "Precision: 83.88%\n",
      "Recall: 84.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,confusion_matrix\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "predictions = np.array([])\n",
    "labels = np.array([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in iter(data_loader):\n",
    "        probs = model(X)\n",
    "        preds = torch.argmax(probs, dim=1, keepdim=False)\n",
    "        predictions = np.concatenate((predictions,preds), axis=None)\n",
    "        labels= np.concatenate((labels,y),axis=None)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(labels,predictions)\n",
    "f1 = f1_score(labels,predictions)\n",
    "precision = precision_score(labels,predictions)\n",
    "recall = recall_score(labels,predictions)\n",
    "\n",
    "names =[\"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\"]\n",
    "functions = [accuracy_score, f1_score, precision_score, recall_score]\n",
    "\n",
    "for name, func in zip(names,functions):\n",
    "    score = func(labels,predictions)\n",
    "    print(f\"{name}: {score*100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists of runs:\n",
    "\n",
    "With SGD:\n",
    "\n",
    "model = NN.LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=4, num_epochs=100, batch_size=64, lr=0.05, verbose='vv') \n",
    "\n",
    "92.62%\n",
    "\n",
    "model = NN.LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=6, num_epochs=100, batch_size=64, lr=0.05, verbose='vv') \n",
    "\n",
    "93.318% (increasing hidden_dim from 4 to 6)\n",
    "\n",
    "\n",
    "With Adam:\n",
    "\n",
    "model = NN.LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=4, num_epochs=100, batch_size=64, lr=0.05, verbose='vv') \n",
    "\n",
    "- Accuracy: 91.81%\n",
    "- F1 Score: 91.82%\n",
    "- Precision: 91.30%\n",
    "- Recall: 92.34%\n",
    "\n",
    "model = NN.LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=9, num_epochs=100, batch_size=64, lr=0.001, verbose='vv')\n",
    "\n",
    "(changed hidden_dim from 4 to 6)\n",
    "\n",
    "\n",
    "- Accuracy: 92.23%\n",
    "- F1 Score: 92.35%\n",
    "- Precision: 90.53%\n",
    "- Recall: 94.25%\n",
    "\n",
    "\n",
    "model = NN.LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=6, num_epochs=100, batch_size=64, lr=0.001, verbose='vv')\n",
    "\n",
    "(changed hidden_dim from 4 to 9)\n",
    "\n",
    "\n",
    "- Accuracy: 92.48%\n",
    "- F1 Score: 92.56%\n",
    "- Precision: 91.22%\n",
    "- Recall: 93.93%\n",
    "\n",
    "\n",
    "model = NN.LSTM.train(dataset=train_data, num_features=num_features, num_blocks=num_blocks, hidden_dim=12, num_epochs=300, batch_size=64, lr=0.001, verbose='vv')\n",
    "\n",
    "(changed hidden_dim from 4 to 12 and num_epochs from 100 to 300)\n",
    "\n",
    "- Accuracy: 92.16%\n",
    "- F1 Score: 92.21%\n",
    "- Precision: 91.25%\n",
    "- Recall: 93.19%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e78a7ef29a5e3028f948eff69c34ba1d8ebd35a887497a02775c6aab840f6bc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
