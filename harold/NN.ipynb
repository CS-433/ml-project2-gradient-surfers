{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## classic pydata stack\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15,7)\n",
    "\n",
    "\n",
    "\n",
    "## torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## SEEDING\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "REBUILD_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr04 = np.load(\"AA00400AA.npy\",allow_pickle=True)\n",
    "arr64 = np.load(\"AA66466AA.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08    , 62.162514],\n",
       "       [ 0.09    , 56.76618 ],\n",
       "       [ 0.1     , 51.997746],\n",
       "       [ 0.11    , 48.05742 ],\n",
       "       [ 0.12    , 44.999798],\n",
       "       [ 0.13    , 42.879486],\n",
       "       [ 0.14    , 41.623676],\n",
       "       [ 0.15    , 41.095875],\n",
       "       [ 0.16    , 41.095875],\n",
       "       [ 0.17    , 41.405277],\n",
       "       [ 0.18    , 41.78748 ],\n",
       "       [ 0.19    , 42.02408 ],\n",
       "       [ 0.2     , 41.91488 ],\n",
       "       [ 0.21    , 41.368877],\n",
       "       [ 0.22    , 40.30417 ],\n",
       "       [ 0.23    , 38.76626 ],\n",
       "       [ 0.24    , 36.809746],\n",
       "       [ 0.25    , 34.57113 ],\n",
       "       [ 0.26    , 32.196014],\n",
       "       [ 0.27    , 29.8664  ],\n",
       "       [ 0.28    , 27.727884],\n",
       "       [ 0.29    , 25.926073],\n",
       "       [ 0.3     , 24.533764],\n",
       "       [ 0.31    , 23.596457],\n",
       "       [ 0.32    , 23.132355],\n",
       "       [ 0.33    , 23.068653],\n",
       "       [ 0.34    , 23.359856],\n",
       "       [ 0.35    , 23.905859],\n",
       "       [ 0.36    , 24.615664],\n",
       "       [ 0.37    , 25.39827 ],\n",
       "       [ 0.38    , 26.171774],\n",
       "       [ 0.39    , 26.899778],\n",
       "       [ 0.4     , 27.536783],\n",
       "       [ 0.41    , 28.082787],\n",
       "       [ 0.42    , 28.54689 ],\n",
       "       [ 0.43    , 28.947292],\n",
       "       [ 0.44    , 29.311295],\n",
       "       [ 0.45    , 29.657097],\n",
       "       [ 0.46    , 30.012   ],\n",
       "       [ 0.47    , 30.385103],\n",
       "       [ 0.48    , 30.785505],\n",
       "       [ 0.49    , 31.213207],\n",
       "       [ 0.5     , 31.67731 ],\n",
       "       [ 0.51    , 32.186913],\n",
       "       [ 0.52    , 32.751118],\n",
       "       [ 0.53    , 33.37902 ],\n",
       "       [ 0.54    , 34.088825],\n",
       "       [ 0.55    , 34.89873 ],\n",
       "       [ 0.56    , 35.82694 ],\n",
       "       [ 0.57    , 36.864346],\n",
       "       [ 0.58    , 37.983654],\n",
       "       [ 0.59    , 39.16666 ],\n",
       "       [ 0.6     , 40.35877 ],\n",
       "       [ 0.61    , 41.478077],\n",
       "       [ 0.62    , 42.451782],\n",
       "       [ 0.63    , 43.216187],\n",
       "       [ 0.64    , 43.671192],\n",
       "       [ 0.65    , 43.79859 ],\n",
       "       [ 0.66    , 43.57109 ],\n",
       "       [ 0.67    , 43.015987],\n",
       "       [ 0.68    , 42.17878 ],\n",
       "       [ 0.69    , 41.141373],\n",
       "       [ 0.7     , 40.031166],\n",
       "       [ 0.71    , 38.95736 ],\n",
       "       [ 0.72    , 38.056454],\n",
       "       [ 0.73    , 37.40125 ],\n",
       "       [ 0.74    , 37.091846],\n",
       "       [ 0.75    , 37.146446],\n",
       "       [ 0.76    , 37.57415 ],\n",
       "       [ 0.77    , 38.311256],\n",
       "       [ 0.78    , 39.26676 ],\n",
       "       [ 0.79    , 40.32237 ],\n",
       "       [ 0.8     , 41.377975],\n",
       "       [ 0.81    , 42.27888 ],\n",
       "       [ 0.82    , 42.943188],\n",
       "       [ 0.83    , 43.32539 ],\n",
       "       [ 0.84    , 43.36179 ],\n",
       "       [ 0.85    , 43.09789 ],\n",
       "       [ 0.86    , 42.56098 ],\n",
       "       [ 0.87    , 41.86028 ],\n",
       "       [ 0.88    , 41.068573],\n",
       "       [ 0.89    , 40.30417 ],\n",
       "       [ 0.9     , 39.658066],\n",
       "       [ 0.91    , 39.193962],\n",
       "       [ 0.92    , 38.96646 ],\n",
       "       [ 0.93    , 38.93916 ],\n",
       "       [ 0.94    , 39.13026 ],\n",
       "       [ 0.95    , 39.439663],\n",
       "       [ 0.96    , 39.803665],\n",
       "       [ 0.97    , 40.113068],\n",
       "       [ 0.98    , 40.30417 ],\n",
       "       [ 0.99    , 40.24957 ],\n",
       "       [ 1.      , 39.921967],\n",
       "       [ 1.01    , 39.30316 ],\n",
       "       [ 1.02    , 38.365856],\n",
       "       [ 1.03    , 37.182846],\n",
       "       [ 1.04    , 35.80874 ],\n",
       "       [ 1.05    , 34.307228],\n",
       "       [ 1.06    , 32.79662 ],\n",
       "       [ 1.07    , 31.349709],\n",
       "       [ 1.08    , 30.0575  ],\n",
       "       [ 1.09    , 28.974592],\n",
       "       [ 1.1     , 28.155588],\n",
       "       [ 1.11    , 27.609585],\n",
       "       [ 1.12    , 27.327482],\n",
       "       [ 1.13    , 27.281982],\n",
       "       [ 1.14    , 27.418482],\n",
       "       [ 1.15    , 27.691484],\n",
       "       [ 1.16    , 28.037287],\n",
       "       [ 1.17    , 28.392189],\n",
       "       [ 1.18    , 28.710691],\n",
       "       [ 1.19    , 28.947292],\n",
       "       [ 1.2     , 29.083794],\n",
       "       [ 1.21    , 29.120193],\n",
       "       [ 1.22    , 29.020094],\n",
       "       [ 1.23    , 28.847193],\n",
       "       [ 1.24    , 28.57419 ],\n",
       "       [ 1.25    , 28.246588],\n",
       "       [ 1.26    , 27.891685],\n",
       "       [ 1.27    , 27.527683],\n",
       "       [ 1.28    , 27.19098 ],\n",
       "       [ 1.29    , 26.899778],\n",
       "       [ 1.3     , 26.663177],\n",
       "       [ 1.31    , 26.517576],\n",
       "       [ 1.32    , 26.472076],\n",
       "       [ 1.33    , 26.508476],\n",
       "       [ 1.34    , 26.681377],\n",
       "       [ 1.35    , 26.97258 ],\n",
       "       [ 1.36    , 27.372982],\n",
       "       [ 1.37    , 27.882586],\n",
       "       [ 1.38    , 28.49229 ],\n",
       "       [ 1.39    , 29.183895],\n",
       "       [ 1.4     , 29.9028  ],\n",
       "       [ 1.41    , 30.649004],\n",
       "       [ 1.42    , 31.377008],\n",
       "       [ 1.43    , 32.059513],\n",
       "       [ 1.44    , 32.66012 ],\n",
       "       [ 1.45    , 33.16972 ],\n",
       "       [ 1.46    , 33.57012 ],\n",
       "       [ 1.47    , 33.843124],\n",
       "       [ 1.48    , 33.997826],\n",
       "       [ 1.49    , 34.052425],\n",
       "       [ 1.5     , 34.006927],\n",
       "       [ 1.51    , 33.906826],\n",
       "       [ 1.52    , 33.770325],\n",
       "       [ 1.53    , 33.642925],\n",
       "       [ 1.54    , 33.55192 ],\n",
       "       [ 1.55    , 33.524624],\n",
       "       [ 1.56    , 33.615623],\n",
       "       [ 1.57    , 33.861324],\n",
       "       [ 1.58    , 34.261726],\n",
       "       [ 1.59    , 34.871433],\n",
       "       [ 1.6     , 35.66314 ],\n",
       "       [ 1.61    , 36.664143],\n",
       "       [ 1.62    , 37.85625 ],\n",
       "       [ 1.63    , 39.20306 ],\n",
       "       [ 1.64    , 40.64087 ],\n",
       "       [ 1.65    , 42.14238 ],\n",
       "       [ 1.66    , 43.58019 ],\n",
       "       [ 1.67    , 44.9179  ],\n",
       "       [ 1.68    , 46.05541 ],\n",
       "       [ 1.69    , 46.910812],\n",
       "       [ 1.7     , 47.438618],\n",
       "       [ 1.71    , 47.575115],\n",
       "       [ 1.72    , 47.329414],\n",
       "       [ 1.73    , 46.71971 ],\n",
       "       [ 1.74    , 45.782406],\n",
       "       [ 1.75    , 44.635796],\n",
       "       [ 1.76    , 43.34359 ],\n",
       "       [ 1.77    , 42.078682],\n",
       "       [ 1.78    , 40.95027 ],\n",
       "       [ 1.79    , 40.103966],\n",
       "       [ 1.8     , 39.639866],\n",
       "       [ 1.81    , 39.648964],\n",
       "       [ 1.82    , 40.15857 ],\n",
       "       [ 1.83    , 41.195976],\n",
       "       [ 1.84    , 42.715683],\n",
       "       [ 1.85    , 44.644897],\n",
       "       [ 1.86    , 46.838013],\n",
       "       [ 1.87    , 49.18583 ],\n",
       "       [ 1.88    , 51.53364 ],\n",
       "       [ 1.89    , 53.690357],\n",
       "       [ 1.9     , 55.55587 ],\n",
       "       [ 1.91    , 56.98458 ],\n",
       "       [ 1.92    , 57.894585],\n",
       "       [ 1.93    , 58.23129 ],\n",
       "       [ 1.94    , 57.994686],\n",
       "       [ 1.95    , 57.212082],\n",
       "       [ 1.96    , 55.938072],\n",
       "       [ 1.97    , 54.236362],\n",
       "       [ 1.98    , 52.225246],\n",
       "       [ 1.99    , 49.986633],\n",
       "       [ 2.      , 47.61152 ],\n",
       "       [ 2.01    , 45.1636  ],\n",
       "       [ 2.02    , 42.697483],\n",
       "       [ 2.03    , 40.258667],\n",
       "       [ 2.04    , 37.85625 ],\n",
       "       [ 2.05    , 35.50844 ],\n",
       "       [ 2.06    , 33.18792 ],\n",
       "       [ 2.07    , 30.931107],\n",
       "       [ 2.08    , 28.747091],\n",
       "       [ 2.09    , 26.681377],\n",
       "       [ 2.1     , 24.752165],\n",
       "       [ 2.11    , 23.077753],\n",
       "       [ 2.12    , 21.694544],\n",
       "       [ 2.13    , 20.720839],\n",
       "       [ 2.14    , 20.202135],\n",
       "       [ 2.15    , 20.220335],\n",
       "       [ 2.16    , 20.802738],\n",
       "       [ 2.17    , 21.967546],\n",
       "       [ 2.18    , 23.669258],\n",
       "       [ 2.19    , 25.853271],\n",
       "       [ 2.2     , 28.392189],\n",
       "       [ 2.21    , 31.185907],\n",
       "       [ 2.22    , 34.088825],\n",
       "       [ 2.23    , 36.955345],\n",
       "       [ 2.24    , 39.639866],\n",
       "       [ 2.25    , 42.00588 ],\n",
       "       [ 2.26    , 43.971493],\n",
       "       [ 2.27    , 45.4639  ],\n",
       "       [ 2.28    , 46.45581 ],\n",
       "       [ 2.29    , 46.929012],\n",
       "       [ 2.3     , 46.929012],\n",
       "       [ 2.31    , 46.50131 ],\n",
       "       [ 2.32    , 45.700504],\n",
       "       [ 2.33    , 44.617596],\n",
       "       [ 2.34    , 43.298088],\n",
       "       [ 2.35    , 41.832977],\n",
       "       [ 2.36    , 40.28597 ],\n",
       "       [ 2.37    , 38.702557],\n",
       "       [ 2.38    , 37.13735 ],\n",
       "       [ 2.39    , 35.635838],\n",
       "       [ 2.4     , 34.207127],\n",
       "       [ 2.41    , 32.878517],\n",
       "       [ 2.42    , 31.70461 ],\n",
       "       [ 2.43    , 30.694504],\n",
       "       [ 2.44    , 29.9028  ],\n",
       "       [ 2.45    , 29.347696],\n",
       "       [ 2.46    , 29.056494],\n",
       "       [ 2.47    , 29.065594],\n",
       "       [ 2.48    , 29.365896],\n",
       "       [ 2.49    , 29.9483  ],\n",
       "       [ 2.5     , 30.803705],\n",
       "       [ 2.51    , 31.868412],\n",
       "       [ 2.52    , 33.069622],\n",
       "       [ 2.53    , 34.33453 ],\n",
       "       [ 2.54    , 35.581238],\n",
       "       [ 2.55    , 36.673244],\n",
       "       [ 2.56    , 37.565052],\n",
       "       [ 2.57    , 38.165653],\n",
       "       [ 2.58    , 38.447758],\n",
       "       [ 2.59    , 38.374954],\n",
       "       [ 2.6     , 37.983654],\n",
       "       [ 2.61    , 37.32845 ],\n",
       "       [ 2.62    , 36.47304 ],\n",
       "       [ 2.63    , 35.50844 ],\n",
       "       [ 2.64    , 34.55293 ],\n",
       "       [ 2.65    , 33.688423],\n",
       "       [ 2.66    , 33.01502 ],\n",
       "       [ 2.67    , 32.55092 ],\n",
       "       [ 2.68    , 32.341614],\n",
       "       [ 2.69    , 32.387115],\n",
       "       [ 2.7     , 32.614616],\n",
       "       [ 2.71    , 32.97862 ],\n",
       "       [ 2.72    , 33.415424],\n",
       "       [ 2.73    , 33.834026],\n",
       "       [ 2.74    , 34.188927],\n",
       "       [ 2.75    , 34.434628],\n",
       "       [ 2.76    , 34.57113 ],\n",
       "       [ 2.77    , 34.60753 ],\n",
       "       [ 2.78    , 34.58933 ],\n",
       "       [ 2.79    , 34.59843 ],\n",
       "       [ 2.8     , 34.70763 ],\n",
       "       [ 2.81    , 34.989735],\n",
       "       [ 2.82    , 35.49024 ],\n",
       "       [ 2.83    , 36.22734 ],\n",
       "       [ 2.84    , 37.201046],\n",
       "       [ 2.85    , 38.384056],\n",
       "       [ 2.86    , 39.639866],\n",
       "       [ 2.87    , 40.904774],\n",
       "       [ 2.88    , 42.04228 ],\n",
       "       [ 2.89    , 42.924988],\n",
       "       [ 2.9     , 43.45279 ],\n",
       "       [ 2.91    , 43.55289 ],\n",
       "       [ 2.92    , 43.197987],\n",
       "       [ 2.93    , 42.406284],\n",
       "       [ 2.94    , 41.250576],\n",
       "       [ 2.95    , 39.821865],\n",
       "       [ 2.96    , 38.265755],\n",
       "       [ 2.97    , 36.709644],\n",
       "       [ 2.98    , 35.317337],\n",
       "       [ 2.99    , 34.207127],\n",
       "       [ 3.      , 33.470024],\n",
       "       [ 3.01    , 33.17882 ],\n",
       "       [ 3.02    , 33.315323],\n",
       "       [ 3.03    , 33.861324],\n",
       "       [ 3.04    , 34.74403 ],\n",
       "       [ 3.05    , 35.86334 ],\n",
       "       [ 3.06    , 37.110046],\n",
       "       [ 3.07    , 38.347656],\n",
       "       [ 3.08    , 39.485165],\n",
       "       [ 3.09    , 40.42247 ],\n",
       "       [ 3.1     , 41.095875],\n",
       "       [ 3.11    , 41.487175],\n",
       "       [ 3.12    , 41.569077],\n",
       "       [ 3.13    , 41.387077],\n",
       "       [ 3.14    , 40.977573],\n",
       "       [ 3.15    , 40.42247 ],\n",
       "       [ 3.16    , 39.767265],\n",
       "       [ 3.17    , 39.11206 ],\n",
       "       [ 3.18    , 38.502357],\n",
       "       [ 3.19    , 38.001854],\n",
       "       [ 3.2     , 37.64695 ],\n",
       "       [ 3.21    , 37.47405 ],\n",
       "       [ 3.22    , 37.46495 ],\n",
       "       [ 3.23    , 37.61055 ],\n",
       "       [ 3.24    , 37.883553],\n",
       "       [ 3.25    , 38.247555],\n",
       "       [ 3.26    , 38.62066 ],\n",
       "       [ 3.27    , 38.930058],\n",
       "       [ 3.28    , 39.139362],\n",
       "       [ 3.29    , 39.175762],\n",
       "       [ 3.3     , 38.97556 ],\n",
       "       [ 3.31    , 38.529655],\n",
       "       [ 3.32    , 37.81985 ],\n",
       "       [ 3.33    , 36.873447],\n",
       "       [ 3.34    , 35.75414 ],\n",
       "       [ 3.35    , 34.50743 ],\n",
       "       [ 3.36    , 33.278923],\n",
       "       [ 3.37    , 32.150513],\n",
       "       [ 3.38    , 31.240509],\n",
       "       [ 3.39    , 30.676304],\n",
       "       [ 3.4     , 30.548904],\n",
       "       [ 3.41    , 30.885605],\n",
       "       [ 3.42    , 31.72281 ],\n",
       "       [ 3.43    , 33.05142 ],\n",
       "       [ 3.44    , 34.80773 ],\n",
       "       [ 3.45    , 36.909847],\n",
       "       [ 3.46    , 39.24856 ],\n",
       "       [ 3.47    , 41.660076],\n",
       "       [ 3.48    , 44.044292],\n",
       "       [ 3.49    , 46.273808],\n",
       "       [ 3.5     , 48.23942 ],\n",
       "       [ 3.51    , 49.877434],\n",
       "       [ 3.52    , 51.12414 ],\n",
       "       [ 3.53    , 51.961346],\n",
       "       [ 3.54    , 52.38905 ],\n",
       "       [ 3.55    , 52.40725 ],\n",
       "       [ 3.56    , 52.052345],\n",
       "       [ 3.57    , 51.333443],\n",
       "       [ 3.58    , 50.286934],\n",
       "       [ 3.59    , 48.949226],\n",
       "       [ 3.6     , 47.329414],\n",
       "       [ 3.61    , 45.5003  ],\n",
       "       [ 3.62    , 43.50739 ],\n",
       "       [ 3.63    , 41.441677],\n",
       "       [ 3.64    , 39.403263],\n",
       "       [ 3.65    , 37.51955 ],\n",
       "       [ 3.66    , 35.93614 ],\n",
       "       [ 3.67    , 34.82593 ],\n",
       "       [ 3.68    , 34.325428],\n",
       "       [ 3.69    , 34.55293 ],\n",
       "       [ 3.7     , 35.590336],\n",
       "       [ 3.71    , 37.43765 ],\n",
       "       [ 3.72    , 40.067566],\n",
       "       [ 3.73    , 43.34359 ],\n",
       "       [ 3.74    , 47.07461 ],\n",
       "       [ 3.75    , 51.03314 ],\n",
       "       [ 3.76    , 54.937065],\n",
       "       [ 3.77    , 58.52249 ],\n",
       "       [ 3.78    , 61.52551 ],\n",
       "       [ 3.79    , 63.736824],\n",
       "       [ 3.8     , 65.019936],\n",
       "       [ 3.81    , 65.29294 ],\n",
       "       [ 3.82    , 64.59223 ],\n",
       "       [ 3.83    , 63.03612 ],\n",
       "       [ 3.84    , 60.761105],\n",
       "       [ 3.85    , 57.994686],\n",
       "       [ 3.86    , 54.964367],\n",
       "       [ 3.87    , 51.897644],\n",
       "       [ 3.88    , 49.012928],\n",
       "       [ 3.89    , 46.44671 ],\n",
       "       [ 3.9     , 44.326397],\n",
       "       [ 3.91    , 42.697483],\n",
       "       [ 3.92    , 41.569077],\n",
       "       [ 3.93    , 40.89567 ],\n",
       "       [ 3.94    , 40.57717 ],\n",
       "       [ 3.95    , 40.54077 ],\n",
       "       [ 3.96    , 40.695473],\n",
       "       [ 3.97    , 40.959373],\n",
       "       [ 3.98    , 41.268776],\n",
       "       [ 3.99    , 41.54178 ],\n",
       "       [ 4.      , 41.78748 ],\n",
       "       [ 4.01    , 41.97858 ],\n",
       "       [ 4.02    , 42.09688 ],\n",
       "       [ 4.03    , 42.14238 ],\n",
       "       [ 4.04    , 42.09688 ],\n",
       "       [ 4.05    , 41.96948 ],\n",
       "       [ 4.06    , 41.696476],\n",
       "       [ 4.07    , 41.286976],\n",
       "       [ 4.08    , 40.70457 ],\n",
       "       [ 4.09    , 39.912865],\n",
       "       [ 4.1     , 38.92096 ],\n",
       "       [ 4.11    , 37.72885 ],\n",
       "       [ 4.12    , 36.354744],\n",
       "       [ 4.13    , 34.86233 ],\n",
       "       [ 4.14    , 33.32442 ],\n",
       "       [ 4.15    , 31.832012],\n",
       "       [ 4.16    , 30.467003],\n",
       "       [ 4.17    , 29.365896],\n",
       "       [ 4.18    , 28.61059 ],\n",
       "       [ 4.19    , 28.273888],\n",
       "       [ 4.2     , 28.419489],\n",
       "       [ 4.21    , 29.074694],\n",
       "       [ 4.22    , 30.212202],\n",
       "       [ 4.23    , 31.768312],\n",
       "       [ 4.24    , 33.661125],\n",
       "       [ 4.25    , 35.73594 ],\n",
       "       [ 4.26    , 37.865353],\n",
       "       [ 4.27    , 39.885567],\n",
       "       [ 4.28    , 41.63278 ],\n",
       "       [ 4.29    , 42.961388],\n",
       "       [ 4.3     , 43.77129 ],\n",
       "       [ 4.31    , 43.998795],\n",
       "       [ 4.32    , 43.59839 ],\n",
       "       [ 4.33    , 42.615585],\n",
       "       [ 4.34    , 41.104973],\n",
       "       [ 4.35    , 39.193962],\n",
       "       [ 4.36    , 36.982647],\n",
       "       [ 4.37    , 34.662132],\n",
       "       [ 4.38    , 32.368916],\n",
       "       [ 4.39    , 30.248602],\n",
       "       [ 4.4     , 28.428589],\n",
       "       [ 4.41    , 26.99078 ],\n",
       "       [ 4.42    , 25.998873],\n",
       "       [ 4.43    , 25.44377 ],\n",
       "       [ 4.44    , 25.325468],\n",
       "       [ 4.45    , 25.57117 ],\n",
       "       [ 4.46    , 26.089874],\n",
       "       [ 4.47    , 26.781479],\n",
       "       [ 4.48    , 27.536783],\n",
       "       [ 4.49    , 28.228388],\n",
       "       [ 4.5     , 28.737991],\n",
       "       [ 4.51    , 28.992794],\n",
       "       [ 4.52    , 28.910892],\n",
       "       [ 4.53    , 28.455889],\n",
       "       [ 4.54    , 27.627785],\n",
       "       [ 4.55    , 26.472076],\n",
       "       [ 4.56    , 25.088867],\n",
       "       [ 4.57    , 23.560057],\n",
       "       [ 4.58    , 22.094948],\n",
       "       [ 4.59    , 20.86644 ],\n",
       "       [ 4.6     , 20.092934],\n",
       "       [ 4.61    , 19.965532],\n",
       "       [ 4.62    , 20.693539],\n",
       "       [ 4.63    , 22.395248],\n",
       "       [ 4.64    , 25.179867],\n",
       "       [ 4.65    , 29.074694],\n",
       "       [ 4.66    , 34.025127],\n",
       "       [ 4.67    , 39.903767],\n",
       "       [ 4.68    , 46.48311 ],\n",
       "       [ 4.69    , 53.544758],\n",
       "       [ 4.7     , 60.761105]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr64[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr64[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = arr04[0]\n",
    "time = obs[:,0]\n",
    "current = obs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [[1,2], [3,4]]\n",
    "[val for sublist in res for val in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 1., 2.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.array([])\n",
    "res = np.concatenate((res,np.array([1,2])),axis=None)\n",
    "np.concatenate((res,np.array([1,2])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divmod(7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(instance, num_blocks):\n",
    "\n",
    "        res = np.array([])\n",
    "        length = len(instance)\n",
    "        # divide the length by num_blocks to get block_size\n",
    "        block_size, remainder  = divmod(length,num_blocks)\n",
    "\n",
    "\n",
    "        # iterating over each block and extracting features\n",
    "        for i in range(num_blocks):\n",
    "\n",
    "            curr = instance[block_size*i: block_size*(i+1)]\n",
    "            features = curr\n",
    "            res = np.concatenate((res, features),axis=None)\n",
    "\n",
    "\n",
    "        ## get the remainder of the time series\n",
    "        curr = instance[block_size*num_blocks:]\n",
    "        features = curr\n",
    "        res = np.concatenate((res,features),axis=None)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1,2,3,4,5,6,7])\n",
    "\n",
    "extract_features(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802.0\n",
      "3.0\n",
      "1599.000312695404\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "list = np.array([1,2,3,4,4000])\n",
    "func = [np.mean,np.median,np.std,len]\n",
    "\n",
    "for f in func:\n",
    "    print(f(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 1.5000, 0.5000, 1.0000, 2.0000, 2.0000, 3.5000, 3.5000, 0.5000,\n",
       "        3.0000, 4.0000, 2.0000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Input(list,2,0)\n",
    "input.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input():\n",
    "    def __init__(self, raw_series,num_blocks,label):\n",
    "        \"\"\" Initilaizes an input object from a raw time series i.e. an input suitable to feed to a recurrent neural network\n",
    "\n",
    "        Args:\n",
    "            raw_series (numpy array of shape (num_timesteps,2)): raw time series from npy data i.e. arr[0] where arr = np.load(\"data.npy\")\n",
    "            num_blocks ([type]): number of \"feature blocks\" into which the time series will be sliced i.e the number of of times we need to feed \n",
    "            to the LSTM to train on the entire time series\n",
    "            label ([type]): Whether it was a \"00\" backbone (label:0) or a \"66\" backbone (label:1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.label = label\n",
    "        self.input = self.process(raw_series,num_blocks)\n",
    "\n",
    "\n",
    "    def process(self,raw_series,num_blocks):\n",
    "        \"\"\" Function that does the entire processing of going from raw time series to a suitable input to feed to a recurrent neural network\n",
    "\n",
    "        Args:\n",
    "            raw_series (numpy array of shape (num_timesteps,2)): raw time series from npy data i.e. arr[0] where arr = np.load(\"data.npy\")\n",
    "            num_blocks ([type]): number of \"feature blocks\" into which the time series will be sliced i.e the number of of times we need to feed \n",
    "            to the LSTM to train on the entire time series\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: array of features from a single raw time series instance\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # stores the processed time series\n",
    "        res = np.array([])\n",
    "\n",
    "        ## returns a list of transformed time series (current list: normal. lowpass filtered, highpass filtered)\n",
    "        instances = self.transform(raw_series)\n",
    "\n",
    "\n",
    "        for instance in instances:\n",
    "            ## chunks an instance of a time series into blocks and extract feature from each block\n",
    "            extracted = self.extract_features(instance,num_blocks)\n",
    "            res = np.concatenate((res,extracted),axis=None)\n",
    "\n",
    "        return torch.Tensor(res)\n",
    "\n",
    "\n",
    "    def transform(self,raw_series):\n",
    "        \"\"\" Given a raw time series, outputs several transformations applied to it\n",
    "            Transformations may be filtering, projecting, ...\n",
    "\n",
    "        Args:\n",
    "            raw_series numpy.ndarray : 1 dimensional array representing the current values\n",
    "\n",
    "        Returns:\n",
    "            List(numpy.ndarray): list of all transformations\n",
    "        \"\"\"\n",
    "\n",
    "        res = [raw_series]\n",
    "\n",
    "        return res\n",
    "\n",
    "    def extract_features(self,instance, num_blocks):\n",
    "\n",
    "        \"\"\" From a time series, divides it into num_blocks blocks and from each block, extract numerical features usable for a neural network\n",
    "\n",
    "        Args:\n",
    "            instance (numpy.ndarray): 1D array containing numerical values\n",
    "            num_blocks (int): number of \"feature blocks\" into which the time series will be sliced i.e the number of of times we need to feed \n",
    "            to the LSTM to train on the entire time series\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: 1D array of length num_blocks*num_features_per_block containing all the features from a time series\n",
    "        \"\"\"\n",
    "\n",
    "        res = np.array([])\n",
    "        length = len(instance)\n",
    "        # divide the length by num_blocks to get block_size\n",
    "        block_size, remainder  = divmod(length,num_blocks)\n",
    "\n",
    "\n",
    "        # iterating over each block and extracting features\n",
    "        for i in range(num_blocks):\n",
    "\n",
    "            curr = instance[block_size*i: block_size*(i+1)]\n",
    "            # get features from block (mean, std, length, ...)\n",
    "            features = self.features(curr)\n",
    "            res = np.concatenate((res, features),axis=None)\n",
    "\n",
    "\n",
    "        ## get the remainder of the time series\n",
    "        ##curr = instance[block_size*num_blocks:]\n",
    "        ##features = self.features(curr)\n",
    "        ##res = np.concatenate((res,features),axis=None)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def features(self,instance):\n",
    "        \"\"\"\n",
    "        From a block of a time series, extracts numerical features usable for a neural network\n",
    "        Args:\n",
    "            instance (numpy.ndarray): 1D array containing numerical values \n",
    "        \"\"\"\n",
    "        res = np.array([])\n",
    "\n",
    "        # list of functions applied to the array for feature extraction\n",
    "        functions = [np.mean,np.median,np.std,np.min,np.max,len]\n",
    "\n",
    "        for func in functions:\n",
    "            res = np.concatenate((res,func(instance)),axis=None)\n",
    "\n",
    "        \n",
    "\n",
    "        return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PolymerDataset(Dataset):\n",
    "    def __init__(self, data_paths,num_blocks):\n",
    "        super().__init__()\n",
    "        self.process(data_paths,num_blocks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "    def process(data_paths, num_blocks):\n",
    "        raw_data = [np.load(data_path, allow_pickle=True) for data_path in data_paths]\n",
    "    \n",
    "    ## balance the dataset by removing signals that are too short or too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7267e+01, 7.9033e+00, 1.8510e+01, 1.0000e-02, 9.8117e+01, 3.2900e+02,\n",
      "        2.1010e+01, 1.1798e+01, 1.7708e+01, 3.3000e+00, 5.3896e+01, 3.2900e+02,\n",
      "        2.2852e+01, 1.1092e+01, 1.7905e+01, 6.5900e+00, 9.9822e+01, 3.2900e+02])\n",
      "tensor([2.3154e+01, 1.2368e+01, 2.8816e+01, 1.0000e-02, 1.0380e+02, 5.2000e+01,\n",
      "        1.5590e+01, 1.0491e+01, 1.6001e+01, 5.3000e-01, 4.5435e+01, 5.2000e+01,\n",
      "        1.9771e+01, 7.3575e+00, 2.5505e+01, 1.0500e+00, 1.0255e+02, 5.2000e+01])\n",
      "tensor([1.8614e+01, 8.1489e+00, 1.7053e+01, 1.0000e-01, 5.5625e+01, 6.4700e+02,\n",
      "        2.1664e+01, 1.2965e+01, 1.3983e+01, 6.5700e+00, 5.4387e+01, 6.4700e+02,\n",
      "        2.5568e+01, 1.8845e+01, 1.2416e+01, 1.0625e+01, 5.7936e+01, 6.4700e+02])\n",
      "tensor([4.4198e+01, 4.1954e+01, 4.4227e+01, 1.0000e-02, 9.5292e+01, 1.2000e+01,\n",
      "        4.5637e+01, 4.2562e+01, 4.5517e+01, 1.3000e-01, 9.4654e+01, 1.2000e+01,\n",
      "        4.8245e+01, 4.7347e+01, 4.7958e+01, 2.5000e-01, 9.9557e+01, 1.2000e+01])\n",
      "tensor([1.7423e+01, 5.7177e+00, 1.7080e+01, 1.2000e-01, 4.9966e+01, 3.2300e+02,\n",
      "        2.1479e+01, 1.0528e+01, 1.8423e+01, 3.3500e+00, 5.4519e+01, 3.2300e+02,\n",
      "        1.9272e+01, 1.1590e+01, 1.2676e+01, 6.5800e+00, 4.9849e+01, 3.2300e+02])\n",
      "tensor([2.1214e+01, 8.3034e+00, 2.4352e+01, 3.0000e-02, 1.0454e+02, 1.1900e+02,\n",
      "        2.0662e+01, 1.1950e+01, 1.9639e+01, 1.2200e+00, 5.3788e+01, 1.1900e+02,\n",
      "        2.0467e+01, 1.0486e+01, 2.0622e+01, 2.4100e+00, 9.4607e+01, 1.1900e+02])\n",
      "tensor([2.0795e+01, 1.0980e+01, 2.3513e+01, 1.0000e-02, 9.8522e+01, 1.8300e+02,\n",
      "        1.6285e+01, 9.5790e+00, 1.5286e+01, 1.8400e+00, 5.3671e+01, 1.8300e+02,\n",
      "        1.6207e+01, 1.0225e+01, 1.4525e+01, 3.6700e+00, 9.2085e+01, 1.8300e+02])\n",
      "tensor([2.2026e+01, 1.2497e+01, 2.2073e+01, 2.0000e-02, 9.9231e+01, 2.6200e+02,\n",
      "        2.1589e+01, 1.0588e+01, 1.8522e+01, 2.6400e+00, 5.3943e+01, 2.6200e+02,\n",
      "        2.3653e+01, 1.3774e+01, 1.8212e+01, 5.2600e+00, 8.9267e+01, 2.6200e+02])\n",
      "tensor([25.9183, 20.5283, 25.5751,  0.1100, 60.5752, 90.0000, 28.0400, 24.9948,\n",
      "        26.6614,  1.0100, 58.5902, 90.0000, 27.9653, 25.4020, 25.7772,  1.9100,\n",
      "        61.6571, 90.0000])\n",
      "tensor([1.9452e+01, 1.0941e+01, 1.8065e+01, 7.0000e-02, 5.7897e+01, 5.8800e+02,\n",
      "        2.2750e+01, 1.2523e+01, 1.5805e+01, 5.9500e+00, 5.5998e+01, 5.8800e+02,\n",
      "        2.4525e+01, 1.7375e+01, 1.2696e+01, 1.1830e+01, 5.7197e+01, 5.8800e+02])\n"
     ]
    }
   ],
   "source": [
    "for arr in arr04[:10]:\n",
    "    input = Input(arr,3,0)\n",
    "    print(input.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super.__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim)\n",
    "        self.fc1 =nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\" Forward pass of our network\n",
    "\n",
    "        Args:\n",
    "            input ([type]): should be our current time series preprocessed with shape(num_blocks, num_features) \n",
    "            where num_blocks is the number of blocks in which we have divided our time series and  num_features is the number of feature per block\n",
    "        \"\"\"\n",
    "        num_blocks=input.shape[0]\n",
    "        ## need to shape the data in 3D tensor for lstm\n",
    "        lstm_out, _ = self.lstm(input.view(num_blocks,1,-1))\n",
    "        ## passing through MLP and softmax\n",
    "        last = self.fc1(lstm_out.view(num_blocks,-1))\n",
    "        scores = F.log_softmax(last,dim=1)\n",
    "\n",
    "        return scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e78a7ef29a5e3028f948eff69c34ba1d8ebd35a887497a02775c6aab840f6bc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
