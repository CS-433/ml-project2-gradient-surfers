{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import *\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_data(data_paths):\n",
    "    rows = []\n",
    "    for data_idx, data_path in enumerate(data_paths):\n",
    "        data = np.load(data_path, allow_pickle=True)\n",
    "        for event in data:\n",
    "            features = build_features(event)\n",
    "            rows.append({'label': data_idx, **features})\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymer_df = process_data(['../data/AA66266AA.npy', '../data/AA66466AA.npy', '../data/AA66566AA.npy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>num_signals</th>\n",
       "      <th>duration</th>\n",
       "      <th>max_current</th>\n",
       "      <th>min_current</th>\n",
       "      <th>mean_current</th>\n",
       "      <th>std_current</th>\n",
       "      <th>num_extrema</th>\n",
       "      <th>mean_extrema</th>\n",
       "      <th>std_extrema</th>\n",
       "      <th>mean_extrema_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>4.32</td>\n",
       "      <td>56.370224</td>\n",
       "      <td>16.413359</td>\n",
       "      <td>34.788353</td>\n",
       "      <td>9.069802</td>\n",
       "      <td>31</td>\n",
       "      <td>18.900551</td>\n",
       "      <td>18.616003</td>\n",
       "      <td>15.244028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>956</td>\n",
       "      <td>9.65</td>\n",
       "      <td>67.736397</td>\n",
       "      <td>42.550556</td>\n",
       "      <td>55.255898</td>\n",
       "      <td>4.654985</td>\n",
       "      <td>79</td>\n",
       "      <td>30.133924</td>\n",
       "      <td>25.596399</td>\n",
       "      <td>8.365108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1485</td>\n",
       "      <td>14.91</td>\n",
       "      <td>65.653435</td>\n",
       "      <td>40.036980</td>\n",
       "      <td>50.781509</td>\n",
       "      <td>4.121673</td>\n",
       "      <td>106</td>\n",
       "      <td>29.375677</td>\n",
       "      <td>22.110746</td>\n",
       "      <td>8.004821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>1.14</td>\n",
       "      <td>55.258640</td>\n",
       "      <td>28.029890</td>\n",
       "      <td>41.888321</td>\n",
       "      <td>8.434102</td>\n",
       "      <td>11</td>\n",
       "      <td>21.684065</td>\n",
       "      <td>22.254078</td>\n",
       "      <td>13.589338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>1.50</td>\n",
       "      <td>41.879601</td>\n",
       "      <td>19.437662</td>\n",
       "      <td>31.943779</td>\n",
       "      <td>5.805984</td>\n",
       "      <td>15</td>\n",
       "      <td>16.416134</td>\n",
       "      <td>16.347281</td>\n",
       "      <td>9.743867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140148</th>\n",
       "      <td>2</td>\n",
       "      <td>1933</td>\n",
       "      <td>19.42</td>\n",
       "      <td>72.652290</td>\n",
       "      <td>23.673409</td>\n",
       "      <td>49.773766</td>\n",
       "      <td>7.695426</td>\n",
       "      <td>159</td>\n",
       "      <td>29.680387</td>\n",
       "      <td>21.369534</td>\n",
       "      <td>12.854592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140149</th>\n",
       "      <td>2</td>\n",
       "      <td>682</td>\n",
       "      <td>6.92</td>\n",
       "      <td>65.707520</td>\n",
       "      <td>21.862839</td>\n",
       "      <td>48.241112</td>\n",
       "      <td>9.603276</td>\n",
       "      <td>51</td>\n",
       "      <td>26.470976</td>\n",
       "      <td>24.333487</td>\n",
       "      <td>16.832687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140150</th>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>1.33</td>\n",
       "      <td>62.715408</td>\n",
       "      <td>38.863491</td>\n",
       "      <td>52.008274</td>\n",
       "      <td>5.030526</td>\n",
       "      <td>13</td>\n",
       "      <td>26.653801</td>\n",
       "      <td>26.358740</td>\n",
       "      <td>10.330729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140151</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>0.99</td>\n",
       "      <td>66.379051</td>\n",
       "      <td>32.530750</td>\n",
       "      <td>53.133121</td>\n",
       "      <td>8.808292</td>\n",
       "      <td>9</td>\n",
       "      <td>27.936756</td>\n",
       "      <td>28.462580</td>\n",
       "      <td>14.161543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140152</th>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>3.08</td>\n",
       "      <td>67.645599</td>\n",
       "      <td>29.156118</td>\n",
       "      <td>50.229252</td>\n",
       "      <td>9.536901</td>\n",
       "      <td>23</td>\n",
       "      <td>26.496374</td>\n",
       "      <td>26.170563</td>\n",
       "      <td>20.037586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140153 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  num_signals  duration  max_current  min_current  mean_current  \\\n",
       "0           0          425      4.32    56.370224    16.413359     34.788353   \n",
       "1           0          956      9.65    67.736397    42.550556     55.255898   \n",
       "2           0         1485     14.91    65.653435    40.036980     50.781509   \n",
       "3           0          109      1.14    55.258640    28.029890     41.888321   \n",
       "4           0          137      1.50    41.879601    19.437662     31.943779   \n",
       "...       ...          ...       ...          ...          ...           ...   \n",
       "140148      2         1933     19.42    72.652290    23.673409     49.773766   \n",
       "140149      2          682      6.92    65.707520    21.862839     48.241112   \n",
       "140150      2          127      1.33    62.715408    38.863491     52.008274   \n",
       "140151      2           88      0.99    66.379051    32.530750     53.133121   \n",
       "140152      2          299      3.08    67.645599    29.156118     50.229252   \n",
       "\n",
       "        std_current  num_extrema  mean_extrema  std_extrema  mean_extrema_diff  \n",
       "0          9.069802           31     18.900551    18.616003          15.244028  \n",
       "1          4.654985           79     30.133924    25.596399           8.365108  \n",
       "2          4.121673          106     29.375677    22.110746           8.004821  \n",
       "3          8.434102           11     21.684065    22.254078          13.589338  \n",
       "4          5.805984           15     16.416134    16.347281           9.743867  \n",
       "...             ...          ...           ...          ...                ...  \n",
       "140148     7.695426          159     29.680387    21.369534          12.854592  \n",
       "140149     9.603276           51     26.470976    24.333487          16.832687  \n",
       "140150     5.030526           13     26.653801    26.358740          10.330729  \n",
       "140151     8.808292            9     27.936756    28.462580          14.161543  \n",
       "140152     9.536901           23     26.496374    26.170563          20.037586  \n",
       "\n",
       "[140153 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polymer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/c9bqjyq95q59ngc5v1t0gz_00000gn/T/ipykernel_20159/3185805435.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \"\"\"\n\u001b[0;32m-> 1113\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1114\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \"\"\"\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1356\u001b[0m                 \u001b[0;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                 \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "label = 'label'\n",
    "features = list(set(polymer_df.columns) - set([label]))\n",
    "\n",
    "train_df, test_df = train_test_split(polymer_df, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(train_df[features], train_df[label])\n",
    "\n",
    "preds = model.predict(test_df[features])\n",
    "accuracy_score(test_df[label], preds), f1_score(test_df[label], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7147885649051039, 0.7177447359911406)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "label = 'label'\n",
    "features = list(set(polymer_df.columns) - set([label]))\n",
    "\n",
    "train_df, test_df = train_test_split(polymer_df, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced', min_samples_leaf=4)\n",
    "model.fit(train_df[features], train_df[label])\n",
    "\n",
    "preds = model.predict(test_df[features])\n",
    "accuracy_score(test_df[label], preds), f1_score(test_df[label], preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999796140948148, 0.9999796140142967)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(train_df[features])\n",
    "accuracy_score(train_df[label], preds), f1_score(train_df[label], preds, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34e9dc8c9cd4c2e3341692c7f5472da17e27c062a0f2ac63648b60e63867ef4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
